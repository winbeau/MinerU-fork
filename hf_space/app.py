"""
MinerU PDF è§£æå™¨ - HuggingFace Spaces ZeroGPU ç‰ˆæœ¬
ä½¿ç”¨ monkey-patch è§£å†³ daemonic processes é—®é¢˜
"""

# ============================================
# å…³é”®ï¼šåœ¨å¯¼å…¥ä»»ä½•å…¶ä»–æ¨¡å—ä¹‹å‰è¿›è¡Œ monkey-patch
# ============================================
import os
import sys

# ç¦ç”¨å¤šè¿›ç¨‹ç›¸å…³ç¯å¢ƒå˜é‡
os.environ['MINERU_WORKER_NUM'] = '0'
os.environ['OMP_NUM_THREADS'] = '1'
os.environ['MKL_NUM_THREADS'] = '1'
os.environ['TOKENIZERS_PARALLELISM'] = 'false'

# Monkey-patch: å°† ProcessPoolExecutor æ›¿æ¢ä¸º ThreadPoolExecutor
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor

# ä¿å­˜åŸå§‹çš„ ProcessPoolExecutor
_OriginalProcessPoolExecutor = concurrent.futures.ProcessPoolExecutor

# åˆ›å»ºä¸€ä¸ªå‡çš„ ProcessPoolExecutorï¼Œå®é™…ä½¿ç”¨ ThreadPoolExecutor
class FakeProcessPoolExecutor(ThreadPoolExecutor):
    """ç”¨ ThreadPoolExecutor æ›¿ä»£ ProcessPoolExecutorï¼Œé¿å… daemon è¿›ç¨‹é—®é¢˜"""
    def __init__(self, max_workers=None, mp_context=None, initializer=None, initargs=()):
        # å¿½ç•¥ mp_context å‚æ•°ï¼Œå› ä¸º ThreadPoolExecutor ä¸éœ€è¦
        super().__init__(max_workers=max_workers, initializer=initializer, initargs=initargs)

# æ›¿æ¢
concurrent.futures.ProcessPoolExecutor = FakeProcessPoolExecutor

# åŒæ—¶æ›¿æ¢ multiprocessing.Pool
import multiprocessing
import multiprocessing.pool

class FakePool:
    """ç”¨çº¿ç¨‹æ¨¡æ‹Ÿ multiprocessing.Pool"""
    def __init__(self, processes=None, initializer=None, initargs=(), maxtasksperchild=None, context=None):
        self._executor = ThreadPoolExecutor(max_workers=processes)

    def map(self, func, iterable, chunksize=None):
        return list(self._executor.map(func, iterable))

    def starmap(self, func, iterable, chunksize=None):
        def wrapper(args):
            return func(*args)
        return list(self._executor.map(wrapper, iterable))

    def apply(self, func, args=(), kwds={}):
        future = self._executor.submit(func, *args, **kwds)
        return future.result()

    def apply_async(self, func, args=(), kwds={}, callback=None, error_callback=None):
        future = self._executor.submit(func, *args, **kwds)
        if callback:
            future.add_done_callback(lambda f: callback(f.result()))
        return future

    def close(self):
        self._executor.shutdown(wait=False)

    def terminate(self):
        self._executor.shutdown(wait=False, cancel_futures=True)

    def join(self):
        self._executor.shutdown(wait=True)

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.terminate()
        return False

# æ›¿æ¢ multiprocessing.Pool
multiprocessing.Pool = FakePool
multiprocessing.pool.Pool = FakePool

print("âœ… Monkey-patch applied: ProcessPoolExecutor â†’ ThreadPoolExecutor")

# ============================================
# ç°åœ¨å¯ä»¥å®‰å…¨å¯¼å…¥å…¶ä»–æ¨¡å—
# ============================================
import spaces
import gradio as gr
import tempfile
import time
from pathlib import Path


@spaces.GPU(duration=300)
def parse_document(
    file,
    backend: str = "pipeline",
    lang: str = "ch",
    max_pages: int = 20,
    table_enable: bool = True,
    formula_enable: bool = True,
):
    """GPU åŠ é€Ÿçš„æ–‡æ¡£è§£æå‡½æ•°"""
    import torch

    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"âœ… GPU: {gpu_name} ({gpu_mem:.1f} GB)")
    else:
        print("âŒ No GPU available!")
        return "é”™è¯¯ï¼šGPU ä¸å¯ç”¨", "", 0

    if file is None:
        return "è¯·ä¸Šä¼  PDF æˆ–å›¾ç‰‡æ–‡ä»¶", "", 0

    start_time = time.time()

    try:
        from mineru.cli.common import do_parse, read_fn
        from mineru.version import __version__

        with tempfile.TemporaryDirectory() as output_dir:
            file_path = Path(file.name if hasattr(file, 'name') else file)
            pdf_bytes = read_fn(file_path)
            file_stem = file_path.stem
            end_page = max_pages - 1 if max_pages else 99999

            os.environ['MINERU_VLM_FORMULA_ENABLE'] = str(formula_enable)
            os.environ['MINERU_VLM_TABLE_ENABLE'] = str(table_enable)

            print(f"ğŸ“„ å¼€å§‹è§£æ: {file_stem}")
            print(f"   Backend: {backend}, Language: {lang}, Max pages: {max_pages}")

            do_parse(
                output_dir=output_dir,
                pdf_file_names=[file_stem],
                pdf_bytes_list=[pdf_bytes],
                p_lang_list=[lang],
                backend=backend,
                parse_method="auto",
                formula_enable=formula_enable,
                table_enable=table_enable,
                f_draw_layout_bbox=False,
                f_draw_span_bbox=False,
                f_dump_md=True,
                f_dump_middle_json=False,
                f_dump_model_output=False,
                f_dump_orig_pdf=False,
                f_dump_content_list=False,
                start_page_id=0,
                end_page_id=end_page,
            )

            # ç¡®å®šç»“æœè·¯å¾„
            if backend == "pipeline":
                result_dir = os.path.join(output_dir, file_stem, "auto")
            elif backend.startswith("vlm"):
                result_dir = os.path.join(output_dir, file_stem, "vlm")
            else:
                result_dir = os.path.join(output_dir, file_stem, "hybrid_auto")

            md_path = os.path.join(result_dir, f"{file_stem}.md")
            elapsed = time.time() - start_time

            if os.path.exists(md_path):
                with open(md_path, "r", encoding="utf-8") as f:
                    markdown = f.read()
                status = f"âœ… è§£ææˆåŠŸï¼è€—æ—¶ {elapsed:.1f} ç§’ (MinerU v{__version__}, GPU: {gpu_name})"
                print(status)
                return status, markdown, elapsed
            else:
                # æŸ¥æ‰¾å¯èƒ½çš„è¾“å‡ºæ–‡ä»¶
                for root, dirs, files in os.walk(output_dir):
                    for f in files:
                        if f.endswith('.md'):
                            md_file = os.path.join(root, f)
                            with open(md_file, "r", encoding="utf-8") as file:
                                markdown = file.read()
                            return f"âœ… è§£ææˆåŠŸï¼è€—æ—¶ {elapsed:.1f} ç§’", markdown, elapsed
                return f"âŒ è§£æå¤±è´¥ï¼šæœªæ‰¾åˆ°è¾“å‡ºæ–‡ä»¶", "", elapsed

    except Exception as e:
        elapsed = time.time() - start_time
        error_msg = f"âŒ è§£æé”™è¯¯: {str(e)}"
        print(error_msg)
        import traceback
        traceback.print_exc()
        return error_msg, "", elapsed


# Gradio ç•Œé¢
with gr.Blocks(title="MinerU PDF è§£æå™¨ (ZeroGPU H200)", theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ğŸ“„ MinerU PDF è§£æå™¨
    ### ğŸš€ Powered by HuggingFace ZeroGPU (NVIDIA H200 70GB)

    å°† PDF/å›¾ç‰‡è½¬æ¢ä¸º Markdown æ ¼å¼ï¼Œæ”¯æŒè¡¨æ ¼ã€å…¬å¼è¯†åˆ«ã€‚
    """)

    with gr.Row():
        with gr.Column(scale=1):
            file_input = gr.File(
                label="ä¸Šä¼ æ–‡ä»¶",
                file_types=[".pdf", ".png", ".jpg", ".jpeg", ".webp", ".gif", ".bmp", ".tiff"],
            )

            backend = gr.Dropdown(
                choices=[
                    ("Pipeline æ¨¡å¼ (æ¨è)", "pipeline"),
                    ("æ··åˆæ¨¡å¼", "hybrid-auto-engine"),
                    ("VLM æ¨¡å¼ (é«˜ç²¾åº¦)", "vlm-auto-engine"),
                ],
                value="pipeline",
                label="è§£æåç«¯",
            )

            lang = gr.Dropdown(
                choices=[
                    ("ä¸­æ–‡", "ch"),
                    ("è‹±æ–‡", "en"),
                    ("è‡ªåŠ¨æ£€æµ‹", "auto"),
                    ("æ—¥æ–‡", "japan"),
                    ("éŸ©æ–‡", "korean"),
                    ("æ‹‰ä¸è¯­ç³»", "latin"),
                ],
                value="ch",
                label="æ–‡æ¡£è¯­è¨€",
            )

            max_pages = gr.Slider(minimum=1, maximum=50, value=10, step=1, label="æœ€å¤§é¡µæ•°")

            with gr.Row():
                table_enable = gr.Checkbox(value=True, label="è¡¨æ ¼è¯†åˆ«")
                formula_enable = gr.Checkbox(value=True, label="å…¬å¼è¯†åˆ«")

            btn = gr.Button("ğŸš€ å¼€å§‹è§£æ", variant="primary", size="lg")

        with gr.Column(scale=2):
            status = gr.Textbox(label="çŠ¶æ€", interactive=False)
            elapsed = gr.Number(label="è€—æ—¶ (ç§’)", interactive=False)
            output = gr.Markdown(label="è§£æç»“æœ")

    btn.click(
        fn=parse_document,
        inputs=[file_input, backend, lang, max_pages, table_enable, formula_enable],
        outputs=[status, output, elapsed],
    )

    gr.Markdown("""
    ---
    ### ğŸ“ è¯´æ˜
    - **Pipeline æ¨¡å¼**: æœ€ç¨³å®šï¼Œæ¨è ZeroGPU ä½¿ç”¨
    - **æ··åˆæ¨¡å¼**: ç»¼åˆç²¾åº¦å’Œé€Ÿåº¦
    - **VLM æ¨¡å¼**: æœ€é«˜ç²¾åº¦ï¼Œé€‚åˆå¤æ‚æ–‡æ¡£

    ### âš ï¸ æ³¨æ„
    - ZeroGPU æœ‰ä½¿ç”¨é…é¢é™åˆ¶
    - å»ºè®®å…ˆç”¨å°æ–‡æ¡£æµ‹è¯•
    """)

if __name__ == "__main__":
    demo.launch()
